import sqlite3
import numpy as np
import pandas as pd
from sentence_transformers import SentenceTransformer
import time
import os
from bertopic import BERTopic
from bertopic.representation import KeyBERTInspired
from bertopic.representation import PartOfSpeech
from bertopic.representation import MaximalMarginalRelevance
from bertopic.vectorizers import ClassTfidfTransformer
from sklearn.cluster import KMeans
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction._stop_words import ENGLISH_STOP_WORDS
from hdbscan import HDBSCAN
import pickle

from recommender.common.constants import DB_PATH

target_links = [
    "scp-6706",
    "scp-6058",
    "numbed-owls-feasting",
    "scp-7775",
    "the-death-of-dr-fern",
    "scp-3929",
    "the-halloween-breach",
    "scp-2762",
    "scp-5992",
    "scp-1321",
    "the-emperor-of-many-voices",
    "tribunal",
    "scp-1823",
    "scp-7268",
    "gdp2-a-little-chat",
    "scp-1644",
    "the-scarlet-truth",
    "scp-6606",
    "test-subjects",
    "scp-3134",
    "scp-3088",
    "milligan-s-truck-story",
    "demoted-to-d-class-part-2",
    "scp-5803",
    "scp-3047",
    "scp-1310",
    "scp-2460",
    "akiva-counter-operating-instructions",
    "until-death-do-us-part",
    "scp-6112",
    "scp-4270",
    "scp-859",
    "scp-006",
    "scp-4961",
    "scp-3829",
    "scp-7171",
    "scp-3724",
    "scp-526",
    "inverted-swiss-cheese",
    "scp-5626",
    "scp-5045",
    "nine-tales-from-the-cativerse",
    "scp-6435",
    "scp-1089",
    "scp-4636",
    "scp-5264",
    "scp-6557",
    "scp-2385",
    "the-ranger-with-the-big-iron-on-his-hip",
    "scp-4633",
    "scp-3489",
    "first-lessons",
    "friday-afternoon",
    "scp-5575",
    "scp-072",
    "scp-7553",
    "scp-7326",
    "the-wasteland",
    "footsteps",
    "scp-6465",
    "scp-5299",
    "waffling-about",
    "moonlighting",
    "scp-6501",
    "scp-4228",
    "the-woven-man",
    "theogenesis",
    "scp-1865",
    "pilgrimage",
    "scp-7952",
    "scp-8023",
    "scp-7585",
    "masayang-palaka",
    "scp-961",
    "heistoween",
    "scp-6046",
    "broadcast",
    "matterminded",
    "scp-7886",
    "scp-1863",
    "the-scent-of-the-worm",
    "scp-4912",
    "amor-pati-or-love-to-suffer",
    "scp-3548",
    "aar-1320-chacaltaya",
    "scp-2229",
    "scp-5762",
    "not-yet",
    "dorer-dances",
    "scp-7008",
    "scp-5284",
    "scp-2609",
    "scp-2346",
    "scp-6988",
    "scp-7639",
    "veilfall",
    "scp-1214",
    "scp-6776",
    "scp-7540",
    "interlude-new-toys",
    "scp-7113",
    "scp-2638",
    "public-static-void",
    "scp-2763",
    "scp-924",
    "scp-2090",
    "scp-1080",
    "scp-8623",
    "nobody-runs-site-19",
    "scp-4641",
    "a-transcribed-collection-of-graffiti-from-site-42",
    "scp-7049",
    "the-case-of-the-missing-hand",
    "heatwave",
    "scp-4542",
    "da-capo-al-fine",
    "scp-6828",
    "scp-3957",
    "whole",
    "urine-over-your-head",
    "hint-the-thing-is-173",
    "scp-7606",
    "scp-6248",
    "scp-3050",
    "disintegration",
    "scp-7894",
    "scp-412",
    "scp-5025",
    "scp-3974",
    "scp-1675",
    "scp-6241",
    "contempt",
    "scp-5729",
    "scp-1955",
    "scp-1335",
    "scp-2595",
    "a-greater-darkness",
    "doctor-cimmerian-cookbook",
    "old-daevite-language",
    "scp-4600",
    "scp-3029",
    "scp-7689",
    "the-place-to-find-yourself",
    "knee-deep-in-the-keter",
    "evolution-of-mind",
    "scp-3323",
    "scp-519",
    "scp-8801",
    "the-decisions-we-make",
    "subliminal-manipulations",
    "scp-2900",
    "scp-1114",
    "scp-3448",
    "d-5111",
    "scp-310",
    "come-wayward-souls",
    "friday",
    "scp-1721",
    "scp-6671",
    "scp-1163",
    "scp-4318",
    "scp-6456",
    "scp-2115",
    "the-spire-star-extended-edition",
    "scp-1425-765",
    "scp-6663",
    "scp-8590",
    "bugs",
    "scp-4943",
    "scp-846",
    "everchase",
    "casefileforsimferopol",
    "scp-8102",
    "scp-2949",
    "scp-4411",
    "scp-6873",
    "jaeger-part-1",
    "and-then-i-died-series-2",
    "the-show-must-always-go-on",
    "scp-1856",
    "scp-1235",
    "time-after-time",
    "scp-7093",
    "scp-6409",
    "a-brief-introduction-to-thaumaturgical-engineering",
    "tempting-fate",
    "stolen-gilded-stolen-saved",
    "uf-00031",
    "scp-5948",
    "elk-rock-island",
    "scp-3969",
    "let-me-borrow-the-map",
    "scp-5808",
    "sweet-cream-pancakes",
    "conversation-2-numberless",
    "scp-5026",
    "a-wandsman-in-the-court-of-the-hanged-king",
    "scp-1680",
    "scp-5677",
    "gohw-chapter-5-dot-js",
    "karen-queen-of-the-monsters",
    "scp-452",
    "cygnus",
    "scp-3992",
    "the-next-best-thing",
    "scp-1990",
    "collected-data",
    "older-roads",
    "meeting-of-the-minds",
    "intelligence-agency-data-archive-subject-mages",
    "scp-5075",
    "scp-2100",
    "scp-1902",
    "scp-1889",
    "scp-994",
    "scp-701",
    "leeway",
    "scp-7420",
    "re-stacks",
    "scp-1968",
    "scp-5073",
    "scp-4571",
    "reg-profile-s11013387",
    "scp-624",
    "scp-7328",
    "scp-7234",
    "scp-8010",
    "scp-3940",
    "every-damn-time",
    "scp-5620",
    "scp-2421",
    "can-you-feel-the-sun",
    "savin-me",
    "heart-of-the-beast",
    "scp-7850",
    "a-bad-miracle",
    "audit-scp-116",
    "online-dating",
    "scp-4833",
    "scp-5861",
    "containment-engineer-a-typical-day",
    "a-new-age-of-magic",
    "scp-1726",
    "2-the-mausoleum-at-ipperwash",
    "scp-6729",
    "goc-supplemental-basic-guide",
    "scp-5920",
    "scp-3516",
    "shuffle-tick-tick",
    "scp-307",
    "scp-5654",
    "scp-6265",
    "ambrose-esterberg",
    "scp-4394",
    "scp-8650",
    "scp-2688",
    "scp-3644",
    "scp-091",
    "scp-548",
    "scp-6253",
    "paradise-lot",
    "8-mr-moon",
    "scp-888",
    "scp-2004",
    "scp-4252",
    "the-runner",
    "tax-man",
    "scp-6796",
    "partial-notes-from-the-corps-of-discovery-expedition-1804-18",
    "scp-1862",
    "scp-7294",
    "lte-1004-caliburn-velveteen",
    "burnin-for-you",
    "scp-3565",
    "leisure-time",
    "scp-7991",
    "patina",
    "scp-4443",
    "scp-7250",
    "scp-6268",
    "scp-322",
    "scp-4514",
    "scp-2681",
    "scp-4532",
    "scp-7602",
    "scp-049-d",
    "scp-3123",
    "in-the-end-we-all-went-out-in-a-blaze",
    "scp-7065",
    "scp-5709",
    "scp-6217",
    "log-of-extranormal-events-vol-ii",
    "last-of-the-hand",
    "scp-7574",
    "price-of-forty-days",
    "scp-849",
    "scp-2442",
    "pitch-black",
    "the-four-arcana",
    "scp-3235",
    "burger-king",
    "spc-179",
    "for-elise",
    "the-trouble-with-amnestics",
    "faith-of-the-foundation",
    "days-gone-by",
    "creative-differences",
    "scp-2648",
    "scp-6473",
    "foundation-unmasked",
    "christmas-dinner",
    "scp-6769",
    "scp-4851",
    "scp-2806",
    "scp-252",
    "scp-8020",
    "scp-5227",
    "at-the-library",
    "drunkenly-stumbling-down-memory-lane",
    "exactly-what-happened",
    "breaker-1-9",
    "scp-4618",
    "scp-7265",
    "the-cave-and-the-garden",
    "scp-3998",
    "the-ironclad-fae",
    "alight",
    "more-than-rhythm",
    "the-countless-first-briefing",
    "scp-5521",
    "scp-4079",
    "closed-game",
    "scp-1401",
    "wayward-repel",
    "dining-out",
    "scp-2463",
    "scp-2687",
    "scp-5770",
    "scp-6450",
    "scp-2476",
    "scp-3758",
    "scp-8002",
    "scp-6546",
    "incident-ta-05-003-1",
    "scp-4568",
    "thereisnocolouroutofspace",
    "the-tale-of-the-library",
    "how-not-to-misappropriate-foundation-resources",
    "scp-688",
    "scp-978",
    "scp-2510",
    "cracked-and-broken",
    "the-book-of-mathisi-chapter-1",
    "the-character-assassination-of-site-666-by-theta-90-a-poem",
    "scp-3539",
    "scp-5716",
    "origin-one-day-your-toes-may-reach-the-trees",
    "nothing-says-promotion-like-a-bag-over-your-head",
    "scp-4563",
    "mind-your-manners",
    "revelations-of-the-author",
    "dust-and-shopper-s-rewards",
    "scp-6858",
    "deus-vulture",
    "tradition",
    "scp-4987",
    "i-care-because-you-do",
    "scp-7622",
    "investigative-journalism",
    "conspiracy-part-v",
    "scp-5844",
    "scp-1450",
    "scp-4385",
    "scp-6837",
    "scp-3292",
    "you-can-see-it-coming",
    "scp-8343",
    "scp-2622",
    "scp-4880",
    "there-be-dragons-in-my-backyard",
    "scp-1890",
    "scp-4569",
    "scp-7673",
    "circumstances",
    "scp-4415",
    "the-beat-of-rain-upon-the-land-broken-teardrop-in-my-hand",
    "scp-1894",
    "a-crooked-brow",
    "scp-3013",
    "scp-042",
    "scp-5602",
    "armageddon",
    "fall-witness-part-1",
    "who-wants-to-live-forever",
    "incursion",
    "an-alchemist-goes-to-war",
    "hour-zero",
    "those-dazed-eyes",
    "scp-6819",
    "scp-5580",
    "scp-676",
    "totally-not-guns-akimbo",
    "scp-4903",
    "scp-1180",
    "scp-6425",
    "scp-3504",
    "melody-for-a-tortured-soul",
    "scp-1771",
    "scp-628",
    "hoovesandantlers",
    "site-81-community-cookbook",
    "scp-3160",
    "micky-d-s",
    "surgery",
    "scp-6412",
    "the-streamliner",
    "reporting-on-the-front",
    "scp-8666",
    "scp-631",
    "scp-3867",
    "taking-the-reinz",
    "they-are-laughing-at-you",
    "scp-5161",
    "no-one-dies-alone",
    "scp-4811",
    "the-asylum",
    "scp-5131",
    "april-9th-2690",
    "scp-1130",
    "scp-829",
    "scp-2986",
    "that-goddamn-thing",
    "scp-640",
    "peanut-butter-crunch",
    "the-lockdown",
    "37-rat-movies-starring-lana-neal",
    "of-wounds-of-the-spirit-inflicted-by-teeth",
    "if-a-bear-shits-in-the-woods-does-it-make-a-sound",
    "scp-7927",
    "scp-775",
    "nor-gloom-of-night-shall-stay",
    "out-of-your-element",
    "scp-7273",
    "domo-arigato",
    "breaching-boredom",
    "its-not-pronounced-like-the-thesaurus-dammit",
    "scp-5483",
    "scp-4303",
    "ieva-breathes",
    "rhythmic-periscope",
    "insignificance",
    "scp-6096",
    "cut-bodies-cut-love",
    "land-of-honey",
    "scp-4067",
    "scp-2058",
    "scp-1575",
    "scp-293",
    "cater-duty",
    "scp-378",
    "stray",
    "scp-2535",
    "scp-1679",
    "scp-5988",
    "scp-6746",
    "scp-8899",
    "scp-3395",
    "whack-a-mole",
    "scp-3023",
    "scp-3110",
    "scp-218",
    "sunfire",
    "scp-7720",
    "scp-6664",
    "makeup",
    "cursed",
    "cryogenchaos-comment-tales",
    "scp-3797",
    "doctor-ronald-stimson-s-personnel-file",
    "corvus",
    "scp-2012",
    "night-time-in-the-forest-of-spooks",
    "faulting-the-leylines-a-geological-examination-of-thaumaturg",
    "scp-2413",
    "scp-1841",
    "scp-5747",
    "the-dark-web-dke79-o2rg5-4jlw6",
    "acquisition-log-scp",
    "scp-2380",
    "first-ivady-donation",
    "i-ihp",
    "scp-5771",
    "alice-oezdemir",
    "scp-062",
    "scp-3771",
    "the-amazing-zoltan",
    "scp-1790",
    "scp-860",
    "1st-12th-december-2008",
    "scp-7418",
]


class MySentenceTransformerr(SentenceTransformer):
    def encode(self, sentences, batch_size=12, **kwargs):
        return SentenceTransformer.encode(self, sentences, batch_size=12, **kwargs)


def main():
    links = target_links

    # 1. Load a pretrained Sentence Transformer model
    model = MySentenceTransformerr(
        "Alibaba-NLP/gte-base-en-v1.5", trust_remote_code=True
    )

    # start = time.time()
    # with sqlite3.connect(DB_PATH) as con:
    #     cur = con.cursor()
    #
    #     res = cur.execute("SELECT link, text FROM pages WHERE LENGTH(text) > 200 AND link != 'immemorial'")
    #     # res = cur.execute(
    #     #     f"SELECT link, text FROM pages WHERE link IN ({','.join(['?'] * len(links))})",
    #     #     links,
    #     # )
    #     pages = res.fetchall()
    #
    #     res = cur.execute(
    #         "SELECT link, text FROM pages WHERE link = 'immemorial' LIMIT 1"
    #     )
    #     reference = res.fetchone()
    # end = time.time()
    # print(f"sqlite {end-start}s")
    #
    # pages = [reference, *pages]
    # corpus = [row[1] for row in pages]
    #
    # # with open("corpus.txt", "w") as fp:
    # #     for link, text in pages:
    # #         fp.write(f'"{link}",\n')
    #
    # # 2. Calculate embeddings by calling model.encode()
    # start = time.time()
    # embeddings = model.encode(corpus, batch_size=12, show_progress_bar=True)
    # end = time.time()
    # print(f"encode {end-start}s")
    # print(embeddings.shape)
    # # [3, 384]
    #
    # with open("./pages-cache.pickle", "wb") as fp:
    #     pickle.dump(pages, fp)
    # with open("./embeddings-cache.pickle", "wb") as fp:
    #     pickle.dump(embeddings, fp)

    with open("./pages-cache.pickle", "rb") as fp:
        pages = pickle.load(fp)
    with open("./embeddings-cache.pickle", "rb") as fp:
        embeddings = pickle.load(fp)

    # indices = [i for i, (link, text) in enumerate(pages) if len(text) < 200]
    # pages = np.delete(pages, indices, axis=0)
    # embeddings = np.delete(embeddings, indices, axis=0)

    corpus = [row[1] for row in pages]


    # 3. Calculate the embedding similarities
    similarities = model.similarity(embeddings, embeddings)
    print(similarities)
    # tensor([[1.0000, 0.6660, 0.1046],
    #         [0.6660, 1.0000, 0.1411],
    #         [0.1046, 0.1411, 1.0000]])

    t_np = similarities.numpy()  # convert to Numpy array
    df = pd.DataFrame(t_np)  # convert to a dataframe
    df.to_csv("testfile.csv", index=False)  # save to file

    # for i, (link, text) in enumerate(pages):
    #     print(f"{i},{link}")

    with open("corpus.txt", "w") as fp:
        for link, text in pages:
            fp.write(f"{link}\n")

    representation_model = {
        "Main": [
            KeyBERTInspired(top_n_words=15),
            MaximalMarginalRelevance(diversity=0.3),
        ]
    }
    topic_model = BERTopic(
        embedding_model=model,
        # hdbscan_model=cluster_model,
        representation_model=representation_model,
        vectorizer_model=CountVectorizer(
            stop_words=[
                *list(ENGLISH_STOP_WORDS),
                "scp",
                "foundation",
                "special",
                "containment",
                "procedures",
                "site",
                "personnel",
                "procedure",
                "level",
                "doctor",
                "access",
                "dr",
                "anomalous",
                "anomaly",
                "agent",
                "contain",
                "contained",
                "class",
                "object",
                "item",
                "facility",
                "security",
                "breach",
                "log",
                "entity",
            ]
        ),
        top_n_words=15,
        n_gram_range=(1, 2),
    )
    topics, probs = topic_model.fit_transform(corpus, embeddings=embeddings)
    # new_topics = topic_model.reduce_outliers(
    #     corpus, topics, embeddings=embeddings, strategy="distributions"
    # )

    print(topic_model.get_topic_info())
    print()
    print(topic_model.get_topic_tree(topic_model.hierarchical_topics(corpus)))
    print()
    print(topic_model.get_topic(0))
    return


main()
